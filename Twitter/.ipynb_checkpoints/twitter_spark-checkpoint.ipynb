{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.88:4040\n",
       "SparkContext available as 'sc' (version = 2.4.4, master = local[*], app id = local-1574791015879)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world ! from Trainer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.SparkConf\n",
       "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.SparkConf\n",
       "import org.apache.spark.ml.feature.{RegexTokenizer, StopWordsRemover, StringIndexer, CountVectorizer, CountVectorizerModel, VectorAssembler, IDF, OneHotEncoderEstimator}\n",
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "import org.apache.spark.ml.param.ParamMap\n",
       "conf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@137d2535\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@539d74b3\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.ml.feature.{RegexTokenizer,StopWordsRemover,\n",
    "                                    StringIndexer,CountVectorizer,\n",
    "                                    CountVectorizerModel,VectorAssembler,\n",
    "                                   IDF,OneHotEncoderEstimator}\n",
    "\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "\n",
    "// import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "// import org.apache.spark.ml.evaluation\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "\n",
    "import org.apache.spark.ml.param.ParamMap\n",
    "\n",
    "\n",
    "val conf = new SparkConf().setAll(Map(\n",
    "      \"spark.scheduler.mode\" -> \"FIFO\",\n",
    "      \"spark.speculation\" -> \"false\",\n",
    "      \"spark.reducer.maxSizeInFlight\" -> \"48m\",\n",
    "      \"spark.serializer\" -> \"org.apache.spark.serializer.KryoSerializer\",\n",
    "      \"spark.kryoserializer.buffer.max\" -> \"1g\",\n",
    "      \"spark.shuffle.file.buffer\" -> \"32k\",\n",
    "      \"spark.default.parallelism\" -> \"12\",\n",
    "      \"spark.sql.shuffle.partitions\" -> \"12\",\n",
    "      \"spark.driver.maxResultSize\" -> \"2g\"\n",
    "    ))\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder\n",
    "  .config(conf)\n",
    "  .appName(\"TP Spark : Twitter\")\n",
    "  .getOrCreate()\n",
    "\n",
    "\n",
    "/*******************************************************************************\n",
    "  *\n",
    "  *       TP 3\n",
    "  *\n",
    "  *       - lire le fichier sauvegarder pr√©c√©demment\n",
    "  *       - construire les Stages du pipeline, puis les assembler\n",
    "  *       - trouver les meilleurs hyperparam√®tres pour l'entra√Ænement du pipeline avec une grid-search\n",
    "  *       - Sauvegarder le pipeline entra√Æn√©\n",
    "  *\n",
    "  *       if problems with unimported modules => sbt plugins update\n",
    "  *\n",
    "  ********************************************************************************/\n",
    "\n",
    "println(\"hello world ! from Trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [text: string, words: array<string> ... 2 more fields]\n",
       "cdf: org.apache.spark.sql.DataFrame = [text: string, words: array<string> ... 1 more field]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df:DataFrame = spark\n",
    "        .read\n",
    "        .option(\"header\", true)\n",
    "        .option(\"separator\",\",\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .parquet(\"data.parquet\")\n",
    "        \n",
    "\n",
    "// df.select(\"project_id\", \"name\", \"desc\", \"goal\").show(5)\n",
    "// df.select(\"keywords\", \"final_status\", \"country2\", \"currency2\").show(5)\n",
    "// df.select(\"deadline2\", \"created_at2\", \"launched_at2\", \"days_campaign\").show(5)\n",
    "// df.select(\"hours_prepa\", \"text\")\n",
    "// df.select(\"label\").show()\n",
    "val cdf = df.drop(\"__index_level_0__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer: org.apache.spark.ml.feature.RegexTokenizer = regexTok_2876c84fc117\n",
       "remover: org.apache.spark.ml.feature.StopWordsRemover = stopWords_0512eca57223\n",
       "cvModel: org.apache.spark.ml.feature.CountVectorizer = cntVec_389e1c7061f2\n",
       "idf: org.apache.spark.ml.feature.IDF = idf_c232dcaeb869\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_47e38170de6c\n",
       "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_6058d0ef4f32\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tokenizer = new RegexTokenizer()\n",
    "  .setPattern(\"\\\\W+\")\n",
    "  .setGaps(true)\n",
    "  .setInputCol(\"text\")\n",
    "  .setOutputCol(\"tokens\")\n",
    "// val dfTokenized = tokenizer.transform(cdf)\n",
    "\n",
    "val remover = new StopWordsRemover()\n",
    "  .setInputCol(tokenizer.getOutputCol)\n",
    "  .setOutputCol(\"filtered\")\n",
    "\n",
    "// val dfsw = remover.transform(dfTokenized)\n",
    "\n",
    "val cvModel: CountVectorizer = new CountVectorizer()\n",
    "    .setInputCol(remover.getOutputCol)\n",
    "    .setOutputCol(\"vect\")\n",
    "    .setMinDF(50)\n",
    "\n",
    "// val dfv = cvModel.fit(dfsw).transform(dfsw)\n",
    "\n",
    "val idf = new IDF()\n",
    "    .setInputCol(cvModel.getOutputCol)\n",
    "    .setOutputCol(\"tfidf\")\n",
    "\n",
    "// val dfidf:DataFrame = idf.fit(dfv).transform(dfv)\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(Array(\"tfidf\"))\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "// val df_f = assembler.transform(dfidf).drop(\"text\",\"words\",\"tokens\",\"vect\",\"tfidf\",\"filtered\")\n",
    "\n",
    "val lr = new LogisticRegression()\n",
    "  .setElasticNetParam(0.0)\n",
    "  .setFitIntercept(true)\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setLabelCol(\"label\")\n",
    "  .setStandardization(true)\n",
    "  .setPredictionCol(\"predictions\")\n",
    "  .setRawPredictionCol(\"raw_predictions\")\n",
    "  .setThresholds(Array(0.7, 0.3))\n",
    "  .setTol(1.0e-6)\n",
    "  .setMaxIter(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_a168d63875b8\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, remover,cvModel,idf, assembler,lr ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.PipelineModel = pipeline_a168d63875b8\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+\n",
      "|label|predictions|         probability|\n",
      "+-----+-----------+--------------------+\n",
      "|    0|        0.0|[0.97928474532398...|\n",
      "|    0|        0.0|[0.99956950473540...|\n",
      "|    1|        1.0|[2.43898442362542...|\n",
      "|    0|        0.0|[0.99961480568612...|\n",
      "|    1|        1.0|[8.54685767194050...|\n",
      "|    1|        1.0|[1.93431769717673...|\n",
      "|    1|        1.0|[2.41317265429764...|\n",
      "|    0|        0.0|[0.84248355487316...|\n",
      "|    1|        0.0|[0.73792895281215...|\n",
      "|    0|        0.0|[0.99999606299803...|\n",
      "|    0|        0.0|[0.98488989028026...|\n",
      "|    0|        0.0|[0.99970820005681...|\n",
      "|    1|        1.0|[6.07360426761614...|\n",
      "|    1|        1.0|[1.51391632357596...|\n",
      "|    1|        1.0|[2.34438019719837...|\n",
      "|    1|        1.0|[0.03215887160417...|\n",
      "|    0|        0.0|[0.92983114913638...|\n",
      "|    0|        0.0|[0.93549382588334...|\n",
      "|    0|        0.0|[0.99980005710904...|\n",
      "|    0|        0.0|[0.86232663151075...|\n",
      "|    0|        0.0|[0.99968103804289...|\n",
      "|    0|        0.0|[0.99961348793145...|\n",
      "|    0|        0.0|[0.99999816564768...|\n",
      "|    0|        0.0|[0.99983260915399...|\n",
      "|    0|        0.0|[0.99998626540191...|\n",
      "|    0|        0.0|[0.98880305285946...|\n",
      "|    1|        1.0|[4.46815805946662...|\n",
      "|    1|        1.0|[5.23045910711986...|\n",
      "|    1|        1.0|[3.57641130705721...|\n",
      "|    1|        1.0|[1.11794374699637...|\n",
      "|    1|        1.0|[2.22339385015037...|\n",
      "|    1|        1.0|[1.41500478241116...|\n",
      "|    1|        1.0|[2.57053146950410...|\n",
      "|    1|        1.0|[2.05419329430895...|\n",
      "|    0|        0.0|[0.99981000420793...|\n",
      "|    0|        0.0|[0.97775364222184...|\n",
      "|    1|        1.0|[2.26809624132715...|\n",
      "|    1|        1.0|[3.38313615734072...|\n",
      "|    1|        1.0|[1.22523337584661...|\n",
      "|    1|        1.0|[4.49769435601966...|\n",
      "|    0|        0.0|[0.99850123231871...|\n",
      "|    1|        0.0|[0.77100788680365...|\n",
      "|    1|        1.0|[1.23170378262195...|\n",
      "|    1|        1.0|[4.04551137866611...|\n",
      "|    0|        0.0|[0.97028551903728...|\n",
      "|    1|        1.0|[2.06052094205584...|\n",
      "|    0|        0.0|[0.87223236593216...|\n",
      "|    1|        1.0|[6.67137822382589...|\n",
      "|    1|        1.0|[7.41347782610610...|\n",
      "|    1|        1.0|[2.72952521225947...|\n",
      "|    1|        1.0|[5.35198332702889...|\n",
      "|    1|        1.0|[3.78955048289214...|\n",
      "|    0|        0.0|[0.98202717740950...|\n",
      "|    1|        1.0|[1.12379483504830...|\n",
      "|    1|        1.0|[9.85695258859435...|\n",
      "|    0|        0.0|[0.96528466346848...|\n",
      "|    1|        1.0|[3.30189791430615...|\n",
      "|    1|        1.0|[1.95783837228613...|\n",
      "|    1|        1.0|[1.23320658124103...|\n",
      "|    1|        1.0|[2.90893573794377...|\n",
      "|    1|        1.0|[2.76493268787041...|\n",
      "|    1|        1.0|[2.09046458995716...|\n",
      "|    1|        1.0|[5.93312972540082...|\n",
      "|    1|        1.0|[4.19104762793332...|\n",
      "|    1|        1.0|[3.05752869003109...|\n",
      "|    1|        1.0|[3.73895746812499...|\n",
      "|    1|        1.0|[2.86283992411824...|\n",
      "|    0|        0.0|[0.98846766700896...|\n",
      "|    1|        1.0|[6.19914360086126...|\n",
      "|    1|        1.0|[2.00685796558688...|\n",
      "|    0|        0.0|[0.99994930558599...|\n",
      "|    1|        1.0|[6.97029105032500...|\n",
      "|    0|        1.0|[0.66712909224250...|\n",
      "|    1|        1.0|[9.28726131017337...|\n",
      "|    0|        1.0|[0.52567649652276...|\n",
      "|    1|        1.0|[0.00135363057342...|\n",
      "|    1|        1.0|[1.06048554616554...|\n",
      "|    1|        1.0|[1.01159404934163...|\n",
      "|    1|        1.0|[2.87472967865033...|\n",
      "|    1|        1.0|[5.32023024569183...|\n",
      "|    1|        1.0|[1.45466416876284...|\n",
      "|    1|        1.0|[3.69213841356135...|\n",
      "|    1|        1.0|[7.11969465125623...|\n",
      "|    1|        1.0|[9.96756238891862...|\n",
      "|    1|        1.0|[0.00298194760824...|\n",
      "|    1|        1.0|[4.22801693194180...|\n",
      "|    1|        1.0|[4.23623260525232...|\n",
      "|    1|        1.0|[1.82852924114659...|\n",
      "|    1|        1.0|[0.00324169407436...|\n",
      "|    0|        0.0|[0.98843848302593...|\n",
      "|    0|        0.0|[0.97799325998595...|\n",
      "|    0|        0.0|[0.99080087165581...|\n",
      "|    0|        0.0|[0.99999749164519...|\n",
      "|    1|        1.0|[5.72751074046448...|\n",
      "|    1|        1.0|[5.18230639119513...|\n",
      "|    1|        1.0|[4.55324716247854...|\n",
      "|    1|        1.0|[3.71145001653425...|\n",
      "|    1|        1.0|[1.30625850153030...|\n",
      "|    1|        1.0|[2.44733854289041...|\n",
      "|    1|        1.0|[4.91881144757852...|\n",
      "+-----+-----------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n",
      "Test set accuracy = 0.9691296428994499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [text: string, words: array<string> ... 2 more fields]\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [text: string, words: array<string> ... 2 more fields]\n",
       "size: (Long, Long) = (2490,620)\n",
       "predictions: org.apache.spark.sql.DataFrame = [text: string, words: array<string> ... 10 more fields]\n",
       "evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_458e8f61e5ff\n",
       "f1: Double = 0.9691296428994499\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train,test) = df.randomSplit(Array[Double](0.8, 0.2))\n",
    "val size = (train.count,test.count)\n",
    "\n",
    "val predictions = model.transform(test)\n",
    "predictions.select(\"label\",\"predictions\",\"probability\").show(100)\n",
    "\n",
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "      .setLabelCol(\"label\")\n",
    "      .setPredictionCol(\"predictions\")\n",
    "      .setMetricName(\"f1\")\n",
    "\n",
    "val f1 = evaluator.evaluate(predictions)\n",
    "println(\"Test set accuracy = \" + f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val a = \"Maldito evo morales\"\n",
    "model.predict('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+\n",
      "|                text|predictions|         probability|\n",
      "+--------------------+-----------+--------------------+\n",
      "|√öLTIMA HORA | Can...|        1.0|[0.46320228452856...|\n",
      "|Lo de los trolls ...|        1.0|[0.04020302526845...|\n",
      "|@Marvazquez92 @Se...|        1.0|[0.17429679658708...|\n",
      "|Michelle Bachelet...|        1.0|[0.09837693466784...|\n",
      "|El embajador aseg...|        1.0|[0.23637814709972...|\n",
      "|#NotiMippCI üì∞üóû|...|        1.0|[0.35945668593017...|\n",
      "|#Bolivia : En men...|        0.0|[0.97557900070806...|\n",
      "|La polic√≠a de Bol...|        1.0|[0.00376085749873...|\n",
      "|Ante la complicid...|        1.0|[0.00970450781144...|\n",
      "|As√≠ act√∫an las di...|        1.0|[0.05964818388108...|\n",
      "|#ENMundo Bolivia ...|        1.0|[0.36970742007131...|\n",
      "|M√ÅS CLARO AGUA. C...|        1.0|[0.08982487716934...|\n",
      "|Denuncian cruelda...|        1.0|[0.12665341113813...|\n",
      "|Uno de los objeti...|        1.0|[0.38564724971603...|\n",
      "|La minor√≠a fascis...|        1.0|[0.14800126002107...|\n",
      "|Bd√≠a,\n",
      "Ante el rep...|        1.0|[0.01272977590316...|\n",
      "|(RT) Gobierno de ...|        1.0|[0.14507045601518...|\n",
      "|Compartimos nota ...|        1.0|[0.14926229640146...|\n",
      "|Claro, did√°ctico,...|        0.0|[0.99963015650410...|\n",
      "|El futuro cancill...|        1.0|[0.21006177824674...|\n",
      "|...\n",
      "¬øCu√°l era el ...|        1.0|[0.11333985717230...|\n",
      "|@ChumelTorres @Ch...|        1.0|[0.23882651199483...|\n",
      "|Ministro de Boliv...|        1.0|[0.27191267710982...|\n",
      "|La neo-nazi Gesta...|        0.0|[0.73226649123657...|\n",
      "|Lo que hay que de...|        1.0|[0.33790523534136...|\n",
      "|Que paso en #chap...|        1.0|[0.08507397165200...|\n",
      "|ATENCI√ìN‚ÄºÔ∏èüõëBOLIV...|        1.0|[3.85629036001526...|\n",
      "|#NOTICIA | Pa√≠ses...|        1.0|[0.43178630900459...|\n",
      "|A los movimientos...|        0.0|[0.76725951573147...|\n",
      "|Los hermanos y he...|        1.0|[0.00112624181330...|\n",
      "|@jmkarg @TwitterL...|        1.0|[0.07002386603537...|\n",
      "|Casualidad ü§®\n",
      "\n",
      "Iv...|        1.0|[0.63477823071050...|\n",
      "|@gabrielacentena ...|        1.0|[0.02202712162850...|\n",
      "|Esto es demasiado...|        0.0|[0.72525829977613...|\n",
      "|@JeanineAnez LA D...|        1.0|[0.02473277289174...|\n",
      "|Comparto ‚ÄúNo pued...|        1.0|[0.28530216973486...|\n",
      "|@ejutv Viva Boliv...|        1.0|[0.07777753833416...|\n",
      "|Muchas gracias a ...|        1.0|[0.12306217264365...|\n",
      "|Tenemos ese tipo ...|        1.0|[0.18262724743670...|\n",
      "|Protestas en Am√©r...|        1.0|[0.00574048742027...|\n",
      "|Mientras te entre...|        1.0|[0.01112755929646...|\n",
      "|@evoespueblo Los ...|        1.0|[0.19626970804648...|\n",
      "|Ser√≠a mejor si de...|        1.0|[0.00779342806437...|\n",
      "|@RicardoBajo @LaR...|        1.0|[0.30033474940839...|\n",
      "|Cuando les pregun...|        1.0|[0.15750917077168...|\n",
      "|Los ind√≠genas que...|        1.0|[0.00333267418280...|\n",
      "|@luigisubversivo ...|        1.0|[0.14909957748319...|\n",
      "|Un Zapatero ‚Äòheri...|        1.0|[0.08929246211294...|\n",
      "|Archivaldo Guzm√°n...|        0.0|[0.92804947092513...|\n",
      "|Radio26| #Matanza...|        1.0|[0.17273885429282...|\n",
      "|Che al final no e...|        1.0|[0.00559495179204...|\n",
      "|#TataQuispe:\n",
      "Grac...|        0.0|[0.99168818412120...|\n",
      "|Hey #pititas! Dic...|        1.0|[0.01027102204643...|\n",
      "|los contundentes ...|        1.0|[0.00616751218628...|\n",
      "|Conosca bien quie...|        1.0|[0.12527940860214...|\n",
      "|L√≠deres soc. y po...|        0.0|[0.98926969332238...|\n",
      "|@marianagc Esta f...|        1.0|[0.20787128850096...|\n",
      "|[#VIDEO] Presiden...|        1.0|[0.24800122363519...|\n",
      "|En Bolivia sigue ...|        1.0|[0.04908106326223...|\n",
      "|Despu√©s de tanta,...|        1.0|[0.54900177388107...|\n",
      "|@evoespueblo @evo...|        1.0|[0.03950595614789...|\n",
      "|@evoespueblo no s...|        0.0|[0.70907361509016...|\n",
      "|Creo eso, si quie...|        1.0|[0.11298165194555...|\n",
      "|Si hay una cosa p...|        1.0|[0.16782400973924...|\n",
      "|@enriqueatigrado ...|        1.0|[0.32470962387727...|\n",
      "|Esta canci√≥n prov...|        0.0|[0.98464022387940...|\n",
      "|@TataQuispe Mucha...|        1.0|[6.90438561007305...|\n",
      "|¬øAs√≠ que las nuev...|        1.0|[0.12248793870336...|\n",
      "|#BTVInforma | Pre...|        1.0|[0.01379932603039...|\n",
      "|72 Horas en #Boli...|        1.0|[0.29233409011984...|\n",
      "|@alssz @LaRazon_B...|        1.0|[0.01786270291879...|\n",
      "|@itsjoelpimentel ...|        1.0|[0.05564369761480...|\n",
      "|Me parece incre√≠b...|        1.0|[0.13965158992296...|\n",
      "|Lo que faltaba......|        1.0|[0.66798322003273...|\n",
      "|Vamos a Bolivia. ...|        0.0|[0.87973420110614...|\n",
      "|No dejen de leer ...|        0.0|[0.70065338744734...|\n",
      "|Camacho y Pumari ...|        1.0|[0.25331452219671...|\n",
      "|@C8Benavides Cami...|        0.0|[0.92110955507421...|\n",
      "|Novaresio _ En Ve...|        1.0|[0.35357574074268...|\n",
      "|Buen√≠simo este ar...|        1.0|[0.00960951153631...|\n",
      "|Dije que el perio...|        0.0|[0.99625712947598...|\n",
      "|@felipe_sola si e...|        0.0|[0.99669112646281...|\n",
      "|#BoliviaResiste\n",
      "#...|        1.0|[0.62830479497615...|\n",
      "|Advierte el minis...|        0.0|[0.72465744279542...|\n",
      "|Hablando con un a...|        1.0|[0.64664870744076...|\n",
      "+--------------------+-----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df_test: org.apache.spark.sql.DataFrame = [created_at: string, text: string ... 9 more fields]\n",
       "a: org.apache.spark.sql.DataFrame = [created_at: string, text: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_test:DataFrame = spark\n",
    "        .read\n",
    "        .option(\"header\", true)\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .parquet(\"test.parquet\")\n",
    "\n",
    "val a = model.transform(df_test)\n",
    "\n",
    "a.select(\"text\",\"predictions\",\"probability\").show(100)\n",
    "// #.show(100,truncate=false)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
